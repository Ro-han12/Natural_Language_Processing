{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'NN': 13162, 'IN': 10616, 'AT': 8893, 'NP': 6866, ',': 5133, 'NNS': 5066, '.': 4452, 'JJ': 4392, 'CC': 2664, 'VBD': 2524, ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common tags in the news category of the Brown Corpus\n",
    "import nltk \n",
    "from  nltk.corpus import brown\n",
    "from nltk import FreqDist\n",
    "tagged_words=brown.tagged_words(categories='news')\n",
    "tagged=nltk.FreqDist(tag for (word,tag)in tagged_words)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PP$',\n",
       " 'DT',\n",
       " 'CC',\n",
       " 'AP',\n",
       " 'NP',\n",
       " ',',\n",
       " 'VBG',\n",
       " 'CD',\n",
       " 'NN-TL',\n",
       " 'VBN',\n",
       " 'OD',\n",
       " '.',\n",
       " 'VB',\n",
       " 'NP$',\n",
       " 'NN$',\n",
       " 'NNS',\n",
       " 'DTI',\n",
       " 'VBD',\n",
       " 'CS',\n",
       " 'NR',\n",
       " 'JJR',\n",
       " '``',\n",
       " 'JJ-TL',\n",
       " 'JJT',\n",
       " 'NNS$',\n",
       " 'NN$-TL',\n",
       " \"''\",\n",
       " 'RB',\n",
       " 'JJS',\n",
       " 'BEZ',\n",
       " 'NP-TL',\n",
       " 'VBZ',\n",
       " 'NNS-TL',\n",
       " 'BEDZ',\n",
       " 'WDT',\n",
       " 'NR$',\n",
       " 'RP',\n",
       " '--',\n",
       " 'WP$',\n",
       " ')',\n",
       " 'ABN',\n",
       " 'NPS$',\n",
       " 'HV',\n",
       " 'PPO',\n",
       " 'WRB',\n",
       " 'BE',\n",
       " 'VBN-TL',\n",
       " 'CD-TL',\n",
       " 'BER',\n",
       " 'NN-HL',\n",
       " 'ABX',\n",
       " 'FW-NN',\n",
       " 'NNS$-TL',\n",
       " '(',\n",
       " 'HVZ',\n",
       " 'DTS',\n",
       " 'BED',\n",
       " 'QL',\n",
       " 'BEN',\n",
       " ':',\n",
       " '*',\n",
       " 'DO',\n",
       " 'NNS-HL',\n",
       " 'FW-DT',\n",
       " 'DTX',\n",
       " \"'\",\n",
       " 'RB-HL',\n",
       " 'PPS+BEZ',\n",
       " 'HVD',\n",
       " 'DOZ',\n",
       " 'AP$',\n",
       " 'NP$-TL',\n",
       " 'DOD',\n",
       " 'AT-TL',\n",
       " 'RB$',\n",
       " 'NR-HL',\n",
       " 'VBN-HL',\n",
       " 'TO',\n",
       " 'CD$',\n",
       " 'PN$',\n",
       " 'HVN',\n",
       " 'OD-TL',\n",
       " 'FW-NN-TL',\n",
       " 'NR$-TL',\n",
       " 'NPS$-TL',\n",
       " ':-HL',\n",
       " '.-HL',\n",
       " 'HVG']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "from  nltk.corpus import brown\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "tagged_words=brown.tagged_words(categories='news')\n",
    "bigram_words=ngrams(tagged_words,2)\n",
    "list(nltk.FreqDist(a[1] for (a, b) in bigram_words if b[1] == 'NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent noun tags:\n",
      "Alice: 2\n",
      "sister: 2\n",
      "book: 2\n",
      "pictures: 2\n",
      "bank: 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "# Sample text data\n",
    "text = \"\"\"\n",
    "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "# Filter the tags to get only nouns\n",
    "nouns = [word for word, pos in pos_tags if pos.startswith('NN')]\n",
    "\n",
    "# Count the frequency of each noun\n",
    "noun_freq = Counter(nouns)\n",
    "\n",
    "# Find the most common noun tags\n",
    "most_common_nouns = noun_freq.most_common(5)  # Change 5 to the desired number of top nouns\n",
    "\n",
    "# Print the results\n",
    "print(\"Most frequent noun tags:\")\n",
    "for noun, frequency in most_common_nouns:\n",
    "    print(f\"{noun}: {frequency}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Sample text data\n",
    "text = \"\"\"\n",
    "Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "# Find words with ambiguous tags\n",
    "ambiguous_words = [(word, tag) for word, tag in pos_tags if len(nltk.help.upenn_tagset(tag)) > 1]\n",
    "\n",
    "# Print the results\n",
    "print(\"Words with ambiguous POS tags:\")\n",
    "for word, tag in ambiguous_words:\n",
    "    print(f\"{word}: {tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Function to create a lookup tagger with a specified size\n",
    "def create_lookup_tagger(size):\n",
    "    words = brown.words()\n",
    "    freq_dist = nltk.FreqDist(words)\n",
    "    top_words = freq_dist.most_common(size)\n",
    "    word_set = set([word for word, _ in top_words])\n",
    "    default_tagger = nltk.DefaultTagger('NN')  # Default tagger assigns 'NN' tag to unknown words\n",
    "    word_tag_pairs = [(word, default_tagger.tag([word])[0][1]) for word in word_set]\n",
    "    return nltk.UnigramTagger(word_tag_pairs)\n",
    "\n",
    "# Main function to create and evaluate lookup taggers of different sizes\n",
    "def main():\n",
    "    # Load the Brown corpus\n",
    "    brown_corpus = brown.tagged_sents(categories='news')\n",
    "\n",
    "    # Define a range of sizes for lookup taggers\n",
    "    sizes = [100, 500, 1000, 2000, 5000]\n",
    "\n",
    "    # Create and evaluate lookup taggers for each size\n",
    "    for size in sizes:\n",
    "        print(f\"Evaluating lookup tagger with size {size}...\")\n",
    "        tagger = create_lookup_tagger(size)\n",
    "        accuracy = tagger.evaluate(brown_corpus)\n",
    "        print(f\"Accuracy for size {size}: {accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8121200039868434"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import UnigramTagger\n",
    "from nltk.corpus import brown\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "size = int(len(brown_tagged_sents) * 0.9)\n",
    "train_sents = brown_tagged_sents[:size]\n",
    "test_sents = brown_tagged_sents[size:]\n",
    "unigram_tagger = nltk.UnigramTagger(train_sents)\n",
    "unigram_tagger.accuracy(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/ipykernel_2632/236216967.py:27: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  accuracy = trigram_tagger.evaluate(brown_corpus)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined tagger accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "# backoff to combine tagger\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
    "from nltk.tag import RegexpTagger\n",
    "\n",
    "# Load the Brown corpus\n",
    "brown_corpus = brown.tagged_sents(categories='news')\n",
    "\n",
    "# Define the backoff taggers\n",
    "default_tagger = DefaultTagger('NN')\n",
    "regex_tagger = RegexpTagger(\n",
    "    [(r'^-?[0-9]+(.[0-9]+)?$', 'CD'),   # cardinal numbers\n",
    "     (r'(The|the|A|a|An|an)$', 'AT'),   # articles\n",
    "     (r'.*able$', 'JJ'),                # adjectives\n",
    "     (r'.*ness$', 'NN'),                # nouns formed from adjectives\n",
    "     (r'.*ly$', 'RB'),                  # adverbs\n",
    "     (r'.*s$', 'NNS'),                  # plural nouns\n",
    "     (r'.*ing$', 'VBG'),                # gerunds\n",
    "     (r'.*ed$', 'VBD'),                 # past tense verbs\n",
    "     (r'.*', 'NN')                      # default noun\n",
    "    ])\n",
    "unigram_tagger = UnigramTagger(brown_corpus, backoff=default_tagger)\n",
    "bigram_tagger = BigramTagger(brown_corpus, backoff=unigram_tagger)\n",
    "trigram_tagger = TrigramTagger(brown_corpus, backoff=bigram_tagger)\n",
    "\n",
    "# Evaluate the combined tagger\n",
    "accuracy = trigram_tagger.evaluate(brown_corpus)\n",
    "print(f\"Combined tagger accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: He will read the book.\n",
      "POS tags: [('He', 'PRP'), ('will', 'MD'), ('read', 'VB'), ('the', 'DT'), ('book', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Sample text with ambiguous words\n",
    "text = \"He will read the book.\"\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Perform part-of-speech tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "# Print the POS tags\n",
    "print(\"Original text:\", text)\n",
    "print(\"POS tags:\", pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
